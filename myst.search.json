{"version":"1","records":[{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook"},"type":"lvl1","url":"/#precipitation-machine-learning-cookbook","position":2},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook"},"content":"\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers an extremely basic precipitation classification project. This notebook will introduce learners to the scikit-learn API, basic exploratory data analysis (EDA), and evaluations. It is meant to be a very early and basic introduction to these concepts, it is not meant to be an in-depth intorduction to machine learning. It could be the first introduction to machine learning for learners familiar with weather data.","type":"content","url":"/#precipitation-machine-learning-cookbook","position":3},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":4},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Motivation"},"content":"This cookbook is meant to be a companion to Unidata’s CyberTraining project.","type":"content","url":"/#motivation","position":5},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":6},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Authors"},"content":"Ana Castaneda Montoya, \n\nThomas Martin","type":"content","url":"/#authors","position":7},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":8},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":9},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":10},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Structure"},"content":"This notebook has a few sections, from inital data loading to a end to end machine learning workflow.","type":"content","url":"/#structure","position":11},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Exploratory Data Analysis","lvl2":"Structure"},"type":"lvl3","url":"/#exploratory-data-analysis","position":12},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Exploratory Data Analysis","lvl2":"Structure"},"content":"This section gives some nice examples of pair plots in Seaborn, and Correlation Matricies.","type":"content","url":"/#exploratory-data-analysis","position":13},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Dataset Splitting","lvl2":"Structure"},"type":"lvl3","url":"/#dataset-splitting","position":14},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Dataset Splitting","lvl2":"Structure"},"content":"For machine learning, we need a testing, training, and validation dataset. This section covers how to do that, and gives some great refrences on the why.","type":"content","url":"/#dataset-splitting","position":15},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Dataset Scaling","lvl2":"Structure"},"type":"lvl3","url":"/#dataset-scaling","position":16},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Dataset Scaling","lvl2":"Structure"},"content":"For (most) machine learning models, scaling is necessary. This sections covers how to do that.","type":"content","url":"/#dataset-scaling","position":17},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Machine Learning (!!!)","lvl2":"Structure"},"type":"lvl3","url":"/#machine-learning","position":18},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Machine Learning (!!!)","lvl2":"Structure"},"content":"The part where we actually train a model! We also see how good it is.","type":"content","url":"/#machine-learning","position":19},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":20},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":21},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":22},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/#running-on-binder","position":23},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":24},{"hierarchy":{"lvl1":"Precipitation Machine Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace “cookbook-example” with the title of your cookbooks)\n\nClone the https://github.com/ThomasMGeo/ptype-ml-cookbook repository: git clone https://github.com/ThomasMGeo/ptype-ml-cookbook.git\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":25},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start"},"type":"lvl1","url":"/notebooks/ptype-ml","position":0},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start"},"content":"\n\n","type":"content","url":"/notebooks/ptype-ml","position":1},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ptype-ml#overview","position":2},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Overview"},"content":"In this cookbook we will go through a simple example showing the Supervised Machine Learning Regression Framework, using the \n\nscikit-learn ecosystem.\n\nReading Data and Exploratory Data Analysis\n\nSplitting Dataset and Scaling Data\n\nTraining, Testing, and Validating Model\n\nThis is a MVP (or minimum viable product) for ML modeling analysis. There are many more things we could test and add to this. The dataset itself is also very small for fast loading and general speed. This CookBook is meant to be a companion to \n\nUnidata’s Cybertraining project.\n\n","type":"content","url":"/notebooks/ptype-ml#overview","position":3},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/ptype-ml#prerequisites","position":4},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nMachine Learning Foundations in the Earth Systems Sciences\n\nNecessary\n\n\n\n10 minutes to pandas\n\nNecessary\n\n\n\nPyplot tutorial\n\nHelpful\n\nNecessary\n\nNumpy: the absolute basics for beginners\n\nGreat to have\n\narrays are the language of machine learning\n\nTime to learn: 45 minutes\n\nWhile it can be easy to get started with the scikit learn syntax, it can take a while to fully understand and learn all of the in’s and out’s of ML systems. This is designed to just be a very quick introduction.\n\n\n\n","type":"content","url":"/notebooks/ptype-ml#prerequisites","position":5},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ptype-ml#imports","position":6},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Imports"},"content":"\n\nUncomment the below line if you need to install the packages below\n\n# pip install numpy pandas seaborn matplotlib pyarrow\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# needed to read in parquet files\nimport pyarrow\n\nWe will do more imports as they come in the notebook.\n\n","type":"content","url":"/notebooks/ptype-ml#imports","position":7},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Read in the data"},"type":"lvl2","url":"/notebooks/ptype-ml#read-in-the-data","position":8},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Read in the data"},"content":"\n\nFirst we will read our data file and examine it’s size. We can also read csv files using the read_csv() function from pandas.\n\ndf = pd.read_parquet(r'../0_data/ptype_sampled.parquet')\n\nmemory_in_megabytes = df.memory_usage(deep=True).sum() / (1024 ** 2)\nprint(f\"The DataFrame size is: {memory_in_megabytes:.2f} MB\")\n\nprint('The shape of the Dataframe is ' + str(df.shape))\n\nSo we have 2000 rows, and 6 columns\n\nLet’s examine the columns of our dataframe:\n\ncolumn_names = df.columns.tolist()\nprint(column_names)\n\nThese names stand for Temperature and Dewpoint Temperature, (both in degrees Celsius), Atmospheric Pressure in Pascals, U and V components of the Wind in meters per second, and finally, Precipitation Type. All of these variables are measured at ground level.\n\n","type":"content","url":"/notebooks/ptype-ml#read-in-the-data","position":9},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Let’s do EDA"},"type":"lvl2","url":"/notebooks/ptype-ml#lets-do-eda","position":10},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Let’s do EDA"},"content":"\n\nAfter we have imported our data, the next step is to explore it. This part is called Exploratory Data Analysis (EDA). The describe() function will give us some descriptive statistics about our columns with numeric values.\n\ndf.describe()\n\nTake a look at the count row, we have 2000 entries in each column, so there is no missing data! Each variable has different means, but some have different standard deviations.\n\nIt is easier to see the relationship between our variables if we plot them:\n\nsns.pairplot(df, hue='ptype')\n\nNotice any trends so far? What input features might be the most important?\n\nNext we can plot the Correlation Matrix. As the name suggests, this will show us the correlation between variables. The closer the absolute value is to 1, the stronger the relationship between these variables is. Notice how all of our diagonal values equal to 1? this is because they represent the correlation between a variable and itself. Can you see which other variables have strong correlations?\n\nFor further reading, visit \n\nCorrelation Matrix, Demystified\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.select_dtypes(include=['number']).corr(), vmin=-1, vmax=1, cmap='coolwarm', annot=True)\nplt.title('Correlation Matrix')\nplt.show()\n\n","type":"content","url":"/notebooks/ptype-ml#lets-do-eda","position":11},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Splitting Datasets"},"type":"lvl2","url":"/notebooks/ptype-ml#splitting-datasets","position":12},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Splitting Datasets"},"content":"\n\nIn this section we will learn how to split our data into the training, validation, and testing sets. As the name suggests, training set is used to teach the model about the data, while validation and testing sets are used to asses the performance of the model.\nTo learn more about the differences between the three, read the following article: \n\nWhat is the Difference Between Test and Validation Datasets? Or browse through this module to also learn more details about the ML framework: \n\nMachine Learning Foundations in the Earth Systems Sciences\n\nfrom sklearn.model_selection import train_test_split\n\nFor this notebook, we will be doing a regression problem. The ptype variable will just be used for EDA. This example uses Temperaturere, Pressure, and Wind Components (x variables) to determine the dewpoint (y variable).\n\nX = df[['TEMP_C_0_m', 'PRES_Pa_0_m','UGRD_m/s_0_m', 'VGRD_m/s_0_m' ]]\ny = df['T_DEWPOINT_C_0_m']\n\n# Splitting into training and temporary set (70% training, 30% temporary)\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Splitting the temporary set into testing and validation sets (20% testing, 10% validation of the original dataset)\nX_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)\n\n","type":"content","url":"/notebooks/ptype-ml#splitting-datasets","position":13},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Scaling Your Data"},"type":"lvl2","url":"/notebooks/ptype-ml#scaling-your-data","position":14},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Scaling Your Data"},"content":"\n\nAfter we split the data, we must scale it. Scaling helps us make sure all features, or variables, contribute equally to the model. We will be using \n\nscikit-learn’s StandardScaler() function, which standardizes our features by substracting the mean from each observation and then dividing by the standard deviation.\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\nIn the following code, the fit_transform() function calculates the mean and standard deviation (fit) of X_train, and then uses those parameters to scale the data (transform).\n\n# Fit the scaler to the training data and transform it\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Transform the testing and validation data using the same scaler\nX_test_scaled = scaler.transform(X_test)\nX_val_scaled = scaler.transform(X_val)\n\nNotice how we are using transform() on our testing and validation data instead. This allows us to use the same mean and invariance as in the training set and keep the testing/validation data “unseen”. This last part is especially important to maintain an unbiased model.\n\nThe following article provides a more detailed explanation: \n\nWhat and why behind fit_transform() and transform() in scikit-learn!\n\nNoteAlways scale datasets after splitting to prevent data leakage!\n\n","type":"content","url":"/notebooks/ptype-ml#scaling-your-data","position":15},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Machine Learning"},"type":"lvl2","url":"/notebooks/ptype-ml#machine-learning","position":16},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Machine Learning"},"content":"\n\n","type":"content","url":"/notebooks/ptype-ml#machine-learning","position":17},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Training","lvl2":"Machine Learning"},"type":"lvl3","url":"/notebooks/ptype-ml#training","position":18},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Training","lvl2":"Machine Learning"},"content":"\n\nWe will use a linear regression model:\n\nfrom sklearn.linear_model import LinearRegression\n\n# Initialize the Logistic Regression model\nmodel = LinearRegression()\n\n# Train the model with the training data\nmodel.fit(X_train_scaled, y_train)\n\nNext step, let’s use the testing data and plot the new predicted values vs true values.\n\n# Predicting the Test set results\ny_pred = model.predict(X_test_scaled)\n\n# Create scatter plot\nplt.scatter(y_test, y_pred, alpha=0.2)\n\n# Add axis labels\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\n\n# Set the same limits for both axes\nmin_val = min(min(y_test), min(y_pred))\nmax_val = max(max(y_test), max(y_pred))\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Add a diagonal line for reference\nplt.plot([min_val, max_val], [min_val, max_val], 'r--')\n\n# Show the plot\nplt.show()\n\n","type":"content","url":"/notebooks/ptype-ml#training","position":19},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Regression Metrics","lvl2":"Machine Learning"},"type":"lvl3","url":"/notebooks/ptype-ml#regression-metrics","position":20},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Regression Metrics","lvl2":"Machine Learning"},"content":"\n\nfrom sklearn.metrics import root_mean_squared_error, r2_score\n\n# Calculate RMSE & R2\nrmse = root_mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"RMSE on Test Set: {rmse:.2f}\")\nprint(f\"R-squared (R2) on Test Set: {r2:.2f}\")\n\nR-squared (R²) and Root Mean Squared Error (RMSE) are both metrics used to evaluate the performance of regression models, but they convey different types of information.\n\nR², also known as the coefficient of determination, measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where a higher value indicates a better fit of the model to the data, with 1 representing a perfect fit.\n\nRMSE, on the other hand, quantifies the average magnitude of the prediction errors, providing an absolute measure of fit in the same units as the dependent variable. It calculates the square root of the average squared differences between predicted and observed values, with a lower RMSE indicating a model that predicts more accurately. While R² gives a sense of how well the model explains the variability of the data, RMSE provides a direct measure of the model’s prediction accuracy.\n\nThis \n\nblog post covers some of the downsides to looking at R2 alone.\n\n","type":"content","url":"/notebooks/ptype-ml#regression-metrics","position":21},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Now let’s try it on the validation set","lvl2":"Machine Learning"},"type":"lvl3","url":"/notebooks/ptype-ml#now-lets-try-it-on-the-validation-set","position":22},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Now let’s try it on the validation set","lvl2":"Machine Learning"},"content":"\n\nAt this point we could make some changes to our model based on the metrics we got after testing and repeat the training and testing process. Once we are done we can proceed to validate model:\n\n# Predicting the Validation set results\ny_val_pred = model.predict(X_val_scaled)\n\n# Calculate RMSE & R2\nrmse_val = root_mean_squared_error(y_val, y_val_pred)\nr2_val = r2_score(y_val, y_val_pred)\n\nprint(f\"RMSE on Validation Set: {rmse_val:.2f}\")\nprint(f\"R-squared (R2) on Validation Set: {r2_val:.2f}\")\n\n","type":"content","url":"/notebooks/ptype-ml#now-lets-try-it-on-the-validation-set","position":23},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Different dataset, different results?"},"type":"lvl2","url":"/notebooks/ptype-ml#different-dataset-different-results","position":24},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Different dataset, different results?"},"content":"\n\nLet’s look at another dataset. This dataset just has snow and freezing rain as the p-types, so overall it will be colder. Let’s see if we get similar results.\n\ndf_frza = pd.read_parquet(r'../0_data/ptype_sampled_frza.parquet')\n\ndf_frza.describe()\n\nsns.pairplot(df_frza, hue='ptype')\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(df_frza.select_dtypes(include=['number']).corr(), vmin=-1, vmax=1, cmap='coolwarm', annot=True)\nplt.title('Correlation Matrix')\nplt.show()\n\nWhat are the differences in EDA compared to rain vs snow? Do you expect this to do better or worse compared to rain vs snow?\n\n","type":"content","url":"/notebooks/ptype-ml#different-dataset-different-results","position":25},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Split up the data & Scale","lvl2":"Different dataset, different results?"},"type":"lvl3","url":"/notebooks/ptype-ml#split-up-the-data-scale","position":26},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Split up the data & Scale","lvl2":"Different dataset, different results?"},"content":"\n\nThe following code is a bit compressed, but is the same line for line as above, just with a new dataset.\n\nX2 = df_frza[['TEMP_C_0_m',  'PRES_Pa_0_m','UGRD_m/s_0_m', 'VGRD_m/s_0_m' ]]\ny2 = df_frza['T_DEWPOINT_C_0_m']\n\n# Splitting into training and temporary set (70% training, 30% temporary)\nX_train2, X_temp2, y_train2, y_temp2 = train_test_split(X2, y2, test_size=0.3, random_state=42)\n\n# Splitting the temporary set into testing and validation sets (20% testing, 10% validation of the original dataset)\nX_test2, X_val2, y_test2, y_val2 = train_test_split(X_temp2, y_temp2, test_size=1/3, random_state=42)\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit the scaler to the training data and transform it\nX_train_scaled2 = scaler.fit_transform(X_train2)\n\n# Transform the testing and validation data using the same scaler\nX_test_scaled2 = scaler.transform(X_test2)\nX_val_scaled2 = scaler.transform(X_val2)\n\nNotice the new model! We will be using a \n\nDecision Tree. If you want to learn more, here is a StatQuest \n\nvideo.\n\n# Decision Tree Regressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()\n\n# Train the model with the training data\nmodel.fit(X_train_scaled2, y_train2)\n\n","type":"content","url":"/notebooks/ptype-ml#split-up-the-data-scale","position":27},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Test Set ML","lvl2":"Different dataset, different results?"},"type":"lvl3","url":"/notebooks/ptype-ml#test-set-ml","position":28},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Test Set ML","lvl2":"Different dataset, different results?"},"content":"\n\n# Predicting the Test set results\ny_pred2 = model.predict(X_test_scaled2)\n\nrmse = root_mean_squared_error(y_test2, y_pred2)\nr2 = r2_score(y_test2, y_pred2)\n\nprint(f\"RMSE on Test Set: {rmse:.2f}\")\nprint(f\"R-squared (R2) on Test Set: {r2:.2f}\")\n\n# Create scatter plot\nplt.scatter(y_test2, y_pred2, alpha=0.2)\n\n# Add axis labels\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\n\n# Set the same limits for both axes\nmin_val = min(min(y_test2), min(y_pred2))\nmax_val = max(max(y_test2), max(y_pred2))\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Add a diagonal line for reference\nplt.plot([min_val, max_val], [min_val, max_val], 'r--')\n\n# Show the plot\nplt.show()\n\nWhat do you notice in this scatter plot compared to the one with rain vs snow?\n\n","type":"content","url":"/notebooks/ptype-ml#test-set-ml","position":29},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Validation Set ML","lvl2":"Different dataset, different results?"},"type":"lvl3","url":"/notebooks/ptype-ml#validation-set-ml","position":30},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"Validation Set ML","lvl2":"Different dataset, different results?"},"content":"\n\n# Predicting the Validation set results\ny_val_pred2 = model.predict(X_val_scaled2)\n\n# Calculate RMSE & R2\nrmse_val = root_mean_squared_error(y_val2, y_val_pred2)\nr2_val = r2_score(y_val2, y_val_pred2)\n\nprint(f\"RMSE on Validation Set: {rmse_val:.2f}\")\nprint(f\"R-squared (R2) on Validation Set: {r2_val:.2f}\")\n\n","type":"content","url":"/notebooks/ptype-ml#validation-set-ml","position":31},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"More Questions","lvl2":"Different dataset, different results?"},"type":"lvl3","url":"/notebooks/ptype-ml#more-questions","position":32},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"More Questions","lvl2":"Different dataset, different results?"},"content":"\n\nWhat do you see comparing the metrics; freezing rain vs snow and snow vs rain? Is this what you expected?\n\nIs the Decision Tree model consistent between testing and validations sets for both experiments? Could we potentially use a more complex model?\n\nHow many lines of code does it take to do a quick ML analysis with a testing, training, and validation dataset?\n\n\n\n","type":"content","url":"/notebooks/ptype-ml#more-questions","position":33},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/ptype-ml#summary","position":34},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Summary"},"content":"In this notebook we learned:\n\nWhat Exploratory Data Analysis is and some useful functions that can help you in the process of understading your data.\n\nHow and why we split and scale data\n\nHow to train your model and evaluate its accuracy afterwards","type":"content","url":"/notebooks/ptype-ml#summary","position":35},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/ptype-ml#whats-next","position":36},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/ptype-ml#whats-next","position":37},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/ptype-ml#resources-and-references","position":38},{"hierarchy":{"lvl1":"Regression ML Analysis - Atmospheric Data Quick Start","lvl2":"Resources and references"},"content":"Scikit-learn\n\nCorrelation Matrix, Demystified\n\nWhat is the Difference Between Test and Validation Datasets?\n\nMachine Learning Foundations in the Earth Systems Sciences\n\nScikit-learn’s StandardScaler Documentation\n\nWhat and why behind fit_transform() and transform() in scikit-learn!\n\nis\nR2: Downsides and Potential Pitfalls for ESS ML Predic\n\nScikit-learn’s Decision Trees\n\nStatQuest video: Decision and Classification Trees, Clearly Explained!!!tion","type":"content","url":"/notebooks/ptype-ml#resources-and-references","position":39}]}